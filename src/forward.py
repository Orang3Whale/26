import numpy as np
import pandas as pd
from scipy.optimize import minimize
import config
from utils import log, save_result
import os
import re

DATA_FILE = config.DATA_RAW / '2026_MCM_Problem_C_Data.csv'
WEEK_FILE = config.DATA_PROCESSED / 'weekly_data_with_popularity.csv'
OUTPUT_FILE = 'votes_estimation_final.csv'

# ==========================================
# 1. æ•°æ®åŠ è½½æ¨¡å—
# ==========================================
def load_and_process_data():
    """è¯»å–åŸå§‹æ•°æ®ï¼Œæ„å»ºèµ›ç¨‹ç»“æ„"""
    if not os.path.exists(DATA_FILE): return {}
    df = pd.read_csv(DATA_FILE)
    
    def parse_elim(res):
        if isinstance(res, str) and res.startswith("Eliminated Week"):
            try: return int(res.split()[-1])
            except: return 999
        return 999 
    
    df['elim_week'] = df['results'].apply(parse_elim)
    
    # è¯†åˆ«æœ€å¤§å‘¨æ•°
    week_cols = [c for c in df.columns if 'week' in c and 'judge' in c]
    max_week = 0
    for c in week_cols:
        m = re.search(r'week(\d+)_', c)
        if m and int(m.group(1)) > max_week:
            max_week = int(m.group(1))
            
    structured_data = {}
    seasons = df['season'].unique()
    
    for s in seasons:
        structured_data[s] = {}
        season_df = df[df['season'] == s]
        for w in range(1, max_week + 1):
            cols = [f'week{w}_judge{j}_score' for j in range(1, 4)]
            cols = [c for c in cols if c in df.columns]
            if not cols: continue
            
            weekly_scores = season_df.set_index('celebrity_name')[cols].sum(axis=1)
            active_contestants = weekly_scores[weekly_scores > 0].index.tolist()
            if not active_contestants: continue
            
            eliminated_list = season_df[season_df['elim_week'] == w]['celebrity_name'].tolist()
            eliminated_name = eliminated_list[0] if eliminated_list else None
            
            structured_data[s][w] = {
                'contestants': active_contestants,
                'eliminated': eliminated_name
            }
    return structured_data 

def load_info():
    """è¯»å–é¢„è®¡ç®—çš„æ¯å‘¨è¾…åŠ©ä¿¡æ¯ï¼ˆäººæ°”ã€æ’åç­‰ï¼‰"""
    if not os.path.exists(WEEK_FILE): return {}
    df = pd.read_csv(WEEK_FILE)
    df.columns = [c.strip() for c in df.columns]
    info_map = {}
    for _, row in df.iterrows():
        key = (row['season'], row['week'], row['celebrity_name'])
        info_map[key] = {
            'weekly_rank': row['weekly_rank'],
            'popularity_ratio': row['popularity_ratio'],
            'weekly_total': row['weekly_total'],
            'eliminated_this_week': row['eliminated_this_week']
        }
    return info_map

# ==========================================
# 2. æ ¸å¿ƒæ•°å­¦é€»è¾‘
# ==========================================

def calculate_alphas(params, contestants, judge_scores_dict, info_map, season, week):
    """
    è®¡ç®— Dirichlet åˆ†å¸ƒçš„å‚æ•° Alpha (æŠ•ç¥¨æ½œåŠ›)
    Alpha = Base + (Pop^Exp * W_Pop) + (Norm_Score * W_Judge)
    """
    base_alpha, w_pop, pop_exp, w_judge = params
    
    # === æ–°å¢ï¼šæ¸©åº¦ç³»æ•° (Temperature) ===
    # T > 1.0: å¢åŠ ä¸ç¡®å®šæ€§ (æ–¹å·®å˜å¤§)ï¼Œæ¥å—ç‡ä¼šæé«˜
    # T < 1.0: å‡å°‘ä¸ç¡®å®šæ€§ (æ–¹å·®å˜å°)ï¼Œæ¥å—ç‡ä¼šé™ä½
    temperature = 2.0  # å»ºè®®å°è¯• 1.5 åˆ° 3.0
    
    alphas = []
    total_score = sum(judge_scores_dict.values()) if judge_scores_dict else 1
    
    for name in contestants:
        key = (season, week, name)
        pop = info_map.get(key, {}).get('popularity_ratio', 0.1)
        if pd.isna(pop): pop = 0.1
        raw_score = judge_scores_dict.get(name, 0)
        norm_score = raw_score / total_score if total_score > 0 else 0
        
        # åŸå§‹è®¡ç®—
        val = base_alpha + (pow(pop, pop_exp) * w_pop) + (norm_score * w_judge)
        
        # åº”ç”¨æ¸©åº¦ç¼©æ”¾ï¼šAlpha è¶Šå°ï¼Œæ–¹å·®è¶Šå¤§ï¼Œåˆ†å¸ƒè¶Šå¹³å¦
        val = val / temperature 
        
        alphas.append(max(0.01, val))
        
    return np.array(alphas)

def rank_sort(judge_ranks_dict, fan_votes_dict):
    """ Rank System: Total Rank (Higher value = Worse) """
    sorted_v = sorted(judge_ranks_dict.keys(), key=lambda x: fan_votes_dict[x], reverse=True)
    v_ranks = {name: i+1 for i, name in enumerate(sorted_v)}
    final_scores = []
    for name in judge_ranks_dict:
        # Judge Rank + Fan Rank
        total = judge_ranks_dict.get(name, 5) + v_ranks[name]
        final_scores.append((name, total))
    # é™åºæ’åˆ—ï¼šåˆ†é«˜è€…(è¡¨ç°å·®)åœ¨å‰
    final_scores.sort(key=lambda x: x[1], reverse=True)
    return final_scores

def percentile_sort(judge_scores_dict, fan_votes_dict):
    """ Percentile System: Total % (Lower value = Worse) """
    tj = sum(judge_scores_dict.values())
    tv = sum(fan_votes_dict.values())
    final_scores = []
    for name in judge_scores_dict:
        pj = judge_scores_dict[name]/tj if tj>0 else 0
        pv = fan_votes_dict[name]/tv if tv>0 else 0
        final_scores.append((name, pj + pv))
    # å‡åºæ’åˆ—ï¼šåˆ†ä½è€…(è¡¨ç°å·®)åœ¨å‰
    final_scores.sort(key=lambda x: x[1])
    return final_scores

# ==========================================
# 3. ä¼˜åŒ–æ¨¡å— (Soft Rank Score)
# ==========================================

def objective_function(params, structure, info_map):
    """
    ç›®æ ‡å‡½æ•°ï¼šæœ€å°åŒ–â€œè½¯æ’åæŸå¤±â€
    ä¸åªçœ‹Top-1æ˜¯å¦å‘½ä¸­ï¼Œè¿˜çœ‹é¢„æµ‹çš„æ·˜æ±°è€…ç¦»å€’æ•°ç¬¬ä¸€æœ‰å¤šè¿‘ã€‚
    """
    if any(p < 0 for p in params): return 1000.0
    if params[2] > 6.0: return 1000.0 # é™åˆ¶æŒ‡æ•°ä¸è¿‡å¤§
    
    total_score = 0
    total_weeks = 0
    
    for s in structure:
        for w in structure[s]:
            data = structure[s][w]
            contestants = data['contestants']
            actual_eliminated = data['eliminated']
            
            if actual_eliminated is None: continue
            
            # å‡†å¤‡æ•°æ®
            current_judge_ranks = {}
            current_judge_scores = {}
            for name in contestants:
                key = (s, w, name)
                if key in info_map:
                    current_judge_ranks[name] = info_map[key]['weekly_rank']
                    current_judge_scores[name] = info_map[key]['weekly_total']
                else:
                    current_judge_ranks[name] = 5
                    current_judge_scores[name] = 20
            
            # è®¡ç®— Alpha
            alphas = calculate_alphas(params, contestants, current_judge_scores, info_map, s, w)
            if alphas is None: return 1000.0
            
            # ä½¿ç”¨æœŸæœ›å€¼ (Expectation) è¿›è¡Œç¡®å®šæ€§é¢„æµ‹
            expected_votes = alphas / alphas.sum()
            vote_dict = {name: v for name, v in zip(contestants, expected_votes)}
            
            predicted_order = []
            
            # ç”Ÿæˆé¢„æµ‹æ’å (å¤´éƒ¨ä¸ºæœ€å¯èƒ½æ·˜æ±°è€…)
            if s <= 2 or s >= 28: # Rank System
                res = rank_sort(current_judge_ranks, vote_dict)
                predicted_order = [x[0] for x in res]
            else: # Percentile System
                res = percentile_sort(current_judge_scores, vote_dict)
                predicted_order = [x[0] for x in res]
            
            # --- è½¯è¯„åˆ†é€»è¾‘ (Soft Rank Scoring) ---
            try:
                rank_index = predicted_order.index(actual_eliminated) # 0 means Correct (Bottom 1)
            except ValueError: continue

            # è¯„åˆ†å¡
            if rank_index == 0:
                week_score = 1.0   # å®Œç¾é¢„æµ‹
            elif rank_index == 1:
                week_score = 0.8   # é¢„æµ‹åœ¨å€’æ•°ç¬¬äºŒ (S28+è¯„å§”æ‹¯æ•‘åŒºï¼Œæˆ–ææ¥è¿‘)
            elif rank_index == 2:
                week_score = 0.5   # é¢„æµ‹åœ¨å€’æ•°ç¬¬ä¸‰ (å±é™©åŒº)
            elif rank_index <= 4:
                week_score = 0.2   # å‹‰å¼ºç›¸å…³
            else:
                week_score = 0.0   # é¢„æµ‹å®Œå…¨åç¦»
            
            total_score += week_score
            total_weeks += 1
            
    if total_weeks == 0: return 1.0
    # ç›®æ ‡æ˜¯æœ€å°åŒ– (1 - å¹³å‡å¾—åˆ†)
    return 1.0 - (total_score / total_weeks)

def optimize_weights(structure, info_map):
    """è¿è¡Œä¼˜åŒ–ç®—æ³•"""
    print("\n" + "="*50)
    print("ğŸš€ å¯åŠ¨å‚æ•°ä¼˜åŒ– (Soft Rank Score Mechanism)...")
    
    # åˆå§‹çŒœæµ‹ [Base, W_Pop, Pop_Exp, W_Judge]
    initial_guess = [1.0, 10.0, 1.5, 5.0]
    
    result = minimize(
        objective_function,
        initial_guess,
        args=(structure, info_map),
        method='Nelder-Mead',
        options={'maxiter': 80, 'disp': True}
    )
    
    best_params = result.x
    final_score = 1.0 - result.fun
    print(f"\nâœ… ä¼˜åŒ–å®Œæˆ! æœ€ä½³è½¯è¯„åˆ†å‡†ç¡®ç‡: {final_score:.2%}")
    print(f"æœ€ä½³å‚æ•°: Base={best_params[0]:.2f}, Pop_W={best_params[1]:.2f}, "
          f"Pop_Exp={best_params[2]:.2f}, Judge_W={best_params[3]:.2f}")
    print("="*50 + "\n")
    return best_params

# ==========================================
# 4. ä¸»ç¨‹åº (Sampling & Metrics)
# ==========================================

def model_main(n_samples=1000, target_season=None):
    structure = load_and_process_data()
    info_map = load_info()
    
    if not structure:
        print("æ— æ•°æ®ï¼Œç»ˆæ­¢ã€‚")
        return

    # 1. è·å–æœ€ä½³æƒé‡ (ä½¿ç”¨ä¹‹å‰çš„ä¼˜åŒ–å‡½æ•°)
    best_params = optimize_weights(structure, info_map)
    
    all_estimates = []
    all_seasons = sorted(structure.keys())
    if target_season:
        all_seasons = [target_season] if target_season in all_seasons else []

    log(f"å¼€å§‹ MCMC é‡‡æ ·ä¸ä¸€è‡´æ€§æ·±åº¦è¯„ä¼° (Samples={n_samples})...")
    
    for s in all_seasons:
        for w in sorted(structure[s].keys()):
            print(f"Processing S{s} W{w}...", end='\r')
            
            data = structure[s][w]
            contestants = data['contestants']
            actual_eliminated = data['eliminated']
            
            # å‡†å¤‡æ•°æ®
            current_judge_ranks = {}
            current_judge_scores = {}
            for name in contestants:
                key = (s, w, name)
                if key in info_map:
                    current_judge_ranks[name] = info_map[key]['weekly_rank']
                    current_judge_scores[name] = info_map[key]['weekly_total']
                else:
                    current_judge_ranks[name] = 5 
                    current_judge_scores[name] = 20

            # --- A. è®¡ç®—å…ˆéªŒåˆ†å¸ƒ (Prior) ---
            alphas = calculate_alphas(best_params, contestants, current_judge_scores, info_map, s, w)
            prior_means = alphas / alphas.sum() # å…ˆéªŒæœŸæœ›æŠ•ç¥¨ç‡
            
            # --- B. MCMC é‡‡æ · (Posterior) ---
            accepted_votes = []
            total_tried = 0
            
            if actual_eliminated is None:
                accepted_votes = np.random.dirichlet(alphas, n_samples)
                total_tried = n_samples
            else:
                while len(accepted_votes) < n_samples:
                    batch = (n_samples - len(accepted_votes)) * 5
                    batch = max(batch, 1000)
                    samples = np.random.dirichlet(alphas, batch)
                    total_tried += batch
                    
                    for i in range(batch):
                        vote_dict = {name: samples[i][j] for j, name in enumerate(contestants)}
                        
                        # çº¦æŸæ£€æŸ¥
                        valid = False
                        if s <= 2 or s >= 28: # Rank
                            res = rank_sort(current_judge_ranks, vote_dict)
                            if s >= 28: valid = actual_eliminated in [x[0] for x in res[:2]]
                            else: valid = res[0][0] == actual_eliminated
                        else: # Percentile
                            res = percentile_sort(current_judge_scores, vote_dict)
                            valid = res[0][0] == actual_eliminated
                        
                        if valid:
                            accepted_votes.append(samples[i])
                            if len(accepted_votes) >= n_samples: break
                    
                    if total_tried > n_samples * 100 and len(accepted_votes) < n_samples * 0.05:
                        break 
            
            # --- C. è®¡ç®—ç»Ÿè®¡é‡ä¸ä¸€è‡´æ€§æŒ‡æ ‡ ---
            if len(accepted_votes) > 0:
                vals = np.array(accepted_votes)
                posterior_means = np.mean(vals, axis=0) # åéªŒæœŸæœ›
                
                # 1. MSE (Distortion): åéªŒä¸å…ˆéªŒçš„å‡æ–¹è¯¯å·®
                # è¡¡é‡ï¼šä¸ºäº†è§£é‡Šç»“æœï¼ŒæŠ•ç¥¨ç‡åç¦»äº†å¸¸ç†å¤šå°‘ï¼Ÿ
                mse_distortion = np.mean((posterior_means - prior_means) ** 2)
                
                # 2. KL Divergence (Approximation): 
                # è¡¡é‡ï¼šä¿¡æ¯å¢ç›Š/æƒŠå¥‡åº¦ (é¿å…log0ï¼ŒåŠ ä¸€ä¸ªå°epsilon)
                epsilon = 1e-9
                kl_divergence = np.sum(posterior_means * np.log((posterior_means + epsilon) / (prior_means + epsilon)))
                
                # 3. Acceptance Rate
                consistency_score = len(accepted_votes) / total_tried
                
                # ç¡®å®šæ€§æŒ‡æ ‡
                std_votes = np.std(vals, axis=0)
                ci_lower = np.percentile(vals, 2.5, axis=0)
                ci_upper = np.percentile(vals, 97.5, axis=0)
                
            else:
                posterior_means = prior_means
                std_votes = np.zeros_like(prior_means)
                ci_lower, ci_upper = prior_means, prior_means
                consistency_score = 0.0
                mse_distortion = 0.0 # æ— æ³•è®¡ç®—ï¼Œæˆ–è€…è®¾ä¸ºæœ€å¤§å€¼
                kl_divergence = 0.0

            # å­˜å…¥åˆ—è¡¨
            for i, name in enumerate(contestants):
                all_estimates.append({
                    'season': s, 
                    'week': w, 
                    'celebrity_name': name,
                    
                    # æ ¸å¿ƒæ•°æ®
                    'vote_mean': posterior_means[i],
                    'prior_mean': prior_means[i], # ä¿å­˜å…ˆéªŒä»¥ä¾¿åç»­åˆ†æ
                    
                    # ç¡®å®šæ€§
                    'vote_std': std_votes[i],
                    'vote_CI_lower': ci_lower[i], 
                    'vote_CI_upper': ci_upper[i],
                    
                    # ä¸€è‡´æ€§/äº‰è®®åº¦æŒ‡æ ‡ (æ•´å‘¨å…±äº«)
                    'consistency_acceptance': consistency_score,
                    'consistency_mse': mse_distortion, # æ–°å¢
                    'consistency_kl': kl_divergence,   # æ–°å¢
                    
                    'is_eliminated': (name == actual_eliminated)
                })

    log(f"\næ‰€æœ‰è®¡ç®—å®Œæˆã€‚")
    result_df = pd.DataFrame(all_estimates)
    save_result(result_df, OUTPUT_FILE)
    log(f"ç»“æœå·²ä¿å­˜è‡³ {OUTPUT_FILE}")
if __name__ == "__main__":
    # ç¤ºä¾‹è¿è¡Œ (n_sampleså»ºè®®è®¾ä¸º10000ä»¥è·å¾—å¹³æ»‘çš„CI)
    model_main(n_samples=2000)